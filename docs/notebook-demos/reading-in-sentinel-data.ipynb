{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in Sentinel-2 Images\n",
    "\n",
    "Sentinel-2 is an observation mission developed by the European Space Agency to\n",
    "monitor the surface of the Earth [official website](http://www.esa.int/Our_Activities/Observing_the_Earth/Copernicus/Sentinel-2).\n",
    "Sets of images are taken of the surface where each image corresponds to a\n",
    "specific wavelength. These images can provide useful data for a wide variety of\n",
    "industries, however, the format they are stored can prove difficult to work\n",
    "with. This being, `JPEG 2000` (file extension `.jp2`), an image compression\n",
    "format for JPEGs that allow for improved quality and compression ratio.\n",
    "\n",
    "There are few programs that can work with `jp2`, which can make processing\n",
    "large amounts of them difficult. Because of GeoPySpark, though, we can leverage\n",
    "the tools available to us in Python that can work with `jp2` and use them to\n",
    "format the sentinel data so that it can be ingested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Data\n",
    "\n",
    "Before we can start this tutorial, we will need to get the sentinel images.\n",
    "All sentinel data can be found on Amazon's S3, and we will be downloading it\n",
    "straight from there.\n",
    "\n",
    "The way the data is stored on S3 will not be discussed here, instead, a general\n",
    "overview of the data will be given. We will downloading three different `jp2`\n",
    "that represent the same area and time in different wavelength. These being:\n",
    "Aerosol detection (443 nm), Water vapor (945 nm), and Cirrus (1375 nm). Why\n",
    "these three bands? It's because of the resolution of the image, which\n",
    "determines what bands are represented best. For this example, we will be\n",
    "working at a 60 m resolution; which provides the best representation of the\n",
    "mentioned bands. As for what is in the photos, it is the eastern coast of\n",
    "Corsica taken on January 4th, 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!curl -o /tmp/B01.jp2 http://sentinel-s2-l1c.s3.amazonaws.com/tiles/32/T/NM/2017/1/4/0/B01.jp2\n",
    "!curl -o /tmp/B09.jp2 http://sentinel-s2-l1c.s3.amazonaws.com/tiles/32/T/NM/2017/1/4/0/B09.jp2\n",
    "!curl -o /tmp/B10.jp2 http://sentinel-s2-l1c.s3.amazonaws.com/tiles/32/T/NM/2017/1/4/0/B10.jp2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Code\n",
    "\n",
    "Now that we have the files, we can begin to read them into GeoPySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "from geopyspark import geopyspark_conf\n",
    "from geopyspark.geotrellis import Tile, Extent, ProjectedExtent\n",
    "from geopyspark.geotrellis import catalog, layer\n",
    "from geopyspark.geotrellis.constants import LayerType, LayoutScheme\n",
    "\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf = geopyspark_conf(master=\"local[*]\", appName=\"ingest-example\")\n",
    "pysc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the JPEG 2000's\n",
    "\n",
    "`rasterio` being backed by GDAL allows us to read in the `jp2`s.\n",
    "Because each image represents a wavelength, there is a order in which\n",
    "they need to be in when they're merged to together into a multiband raster which\n",
    "is represented by `jp2s`. After the reading process, the list of `numpy`\n",
    "arrays will be turned into one array. This represents our mulitband raster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jp2s = [\"/tmp/B01.jp2\", \"/tmp/B09.jp2\", \"/tmp/B10.jp2\"]\n",
    "arrs = []\n",
    "\n",
    "for jp2 in jp2s:\n",
    "    with rasterio.open(jp2) as f:\n",
    "        arrs.append(f.read(1))\n",
    "\n",
    "data = np.array(arrs, dtype=arrs[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint16')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the RDD\n",
    "\n",
    "GeoPySpark is a Python binding of GeoTrellis, and because of that, requires the\n",
    "data to be in a certain format. Please see\n",
    ":ref:`core_concepts` to learn what each of these variables represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extent = Extent(*f.bounds)\n",
    "projected_extent = ProjectedExtent(extent=extent, epsg=int(f.crs.to_dict()['init'][5:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tile = Tile(cells=data, cell_type='USHORT', no_data_value=f.nodata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdd = pysc.parallelize([(projected_extent, tile)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Layer\n",
    "\n",
    "With our RDD, we can now create a `RasterLayer` using the `from_numpy_rdd` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<geopyspark.geotrellis.layer.RasterLayer at 0x7f8fe8253638>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raster_layer = layer.RasterLayer.from_numpy_rdd(pysc=pysc, layer_type=LayerType.SPATIAL, numpy_rdd=rdd)\n",
    "raster_layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
